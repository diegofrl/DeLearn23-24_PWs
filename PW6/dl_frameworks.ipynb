{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expressed-suffering",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "educational-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9ac65-cf2d-4571-93ce-aeb172cbfbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torchvision.datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "labels_map = {\n",
    "    0: \"Airplane\",\n",
    "    1: \"Automobile\",\n",
    "    2: \"Bird\",\n",
    "    3: \"Cat\",\n",
    "    4: \"Deer\",\n",
    "    5: \"Dog\",\n",
    "    6: \"Frog\",\n",
    "    7: \"Horse\",\n",
    "    8: \"Ship\",\n",
    "    9: \"Truck\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7484b6-292a-465f-9077-6b32e1847042",
   "metadata": {},
   "source": [
    "### Create custom dataset\n",
    "\n",
    "The following dataset does the type conversion and normalisation only once in the constructor and then only gives back the prepared images. It uses our previous method `prepare_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ac812-b47b-40ab-9450-bf0091dcb396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"owns dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, classes = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), min_max_normalise=1, flatten=0):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        dataset -- a tuple with the [images, labels] of the original dataset\n",
    "        classes -- list of classes to use for training (at least two classes must be given)\n",
    "        min_max_normalise -- whether to do min-max-normalisation (1) or rescaling (0)\n",
    "        flatten -- whether to flatten the 28x28 image to single row (=1);\n",
    "\n",
    "        \"\"\"\n",
    "        self.prepare_data(dataset, classes, min_max_normalise, flatten)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #add the missing map-dimension\n",
    "        return self.x_sel[idx], self.y_sel[idx]\n",
    "\n",
    "\n",
    "    def prepare_data(self, dataset, classes, min_max_normalise, flatten):\n",
    "        x = dataset[0]\n",
    "        y = dataset[1]\n",
    "    \n",
    "        if len(classes) < len(labels_map):\n",
    "            for label in classes:\n",
    "                print('labels chosen are: %r' % labels_map[label.item()])\n",
    "    \n",
    "        ind_sel = torch.isin(y, classes)\n",
    "    \n",
    "        x_sel = torch.zeros(x[ind_sel,:].shape, dtype=torch.float)\n",
    "        x_sel.copy_(x[ind_sel,:])\n",
    "        y_sel = torch.zeros(y[ind_sel].shape, dtype=y.dtype)\n",
    "        y_sel.copy_(y[ind_sel])\n",
    "    \n",
    "        #replace the labels such that they are in successive order\n",
    "        for i0 in range(0,len(classes)):\n",
    "            if i0 != classes[i0]:\n",
    "                y_sel[y_sel == classes[i0]] = i0\n",
    "    \n",
    "        #we give y back as simple vector -> simplifies handling below\n",
    "        #y_sel = np.reshape(y_sel, (-1,1))\n",
    "        \n",
    "        #do train and test split\n",
    "        self.num_samples = x_sel.shape[0]\n",
    "            \n",
    "        #perform normalisation, take care of converting data type to float!\n",
    "        xmax, xmin = torch.max(x_sel), torch.min(x_sel)\n",
    "        \n",
    "        if min_max_normalise:\n",
    "            x_sel = 2*(x_sel - xmin) / (xmax - xmin) - 1\n",
    "        else:\n",
    "            x_sel = x_sel / xmax \n",
    "    \n",
    "        if flatten:\n",
    "            m = x_sel.shape[0]\n",
    "            x_sel = x_sel.reshape([m,-1])\n",
    "        \n",
    "        self.x_sel = torch.unsqueeze(x_sel,1)\n",
    "        self.y_sel = y_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be8bd0-09fa-4f85-8281-210abf5214ec",
   "metadata": {},
   "source": [
    "### Set output directory for tensorboard\n",
    "\n",
    "This folder is relative to the working path on the hard disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d531c-0b55-4c68-bd68-efff3e3a63b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('tensorboard/fashion_mnist_experiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8a0282-9fa3-4288-a443-39d4dcf1cb45",
   "metadata": {},
   "source": [
    "### we can send images to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe543be1-774a-4503-a354-cd9d335eddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images (add map dimension at position 1)\n",
    "my_images = torch.unsqueeze(training_data.data[:20],1)\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(my_images)\n",
    "\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('a_set_of_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bcd5fb-d25e-4fe5-906e-386c955898a1",
   "metadata": {},
   "source": [
    "### Class NeuralNetwork\n",
    "\n",
    "This class constructs a Multilayer Perceptron with a configurable number of hidden layers. Cost function is CE. The method $propagate()$ returns the prediction $$ \\hat{y}^{(i)}=h_\\theta(\\mathbf{x}^{(i)}) $$ on the input data (can be a n x 784 matrix of n images) and $back\\_propagate()$ determines the gradients of the cost function with respect to the parameters (weights and bias for all layers) $$ \\nabla_{\\mathbf{\\theta}} J(\\mathbf{\\theta}) $$\n",
    "The method $gradient\\_descend()$ finally does the correction of the parameters with a step in the negative gradient direction, weighted with the learning rate $$\\alpha$$ for all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c173bc6-1969-4bd7-87fe-b6807f8529d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    MLP class handling the layers and doing all propagation and back propagation steps\n",
    "    all hidden layers are dense (with ReLU activation) and the last layer is softmax\n",
    "    \"\"\"\n",
    "    def __init__(self, list_num_neurons):\n",
    "        \"\"\"\n",
    "        constructor\n",
    "\n",
    "        Arguments:\n",
    "        list_num_neurons -- list of layer sizes including in- and output layer\n",
    "        \n",
    "        \"\"\"\n",
    "        self.model = torch.nn.Sequential()\n",
    "        #now we require a flatten tensor\n",
    "        self.model.add_module('flatten', torch.nn.Flatten(start_dim=1, end_dim=-1))\n",
    "        #first construct dense layers\n",
    "        for i0 in range(len(list_num_neurons)-2):\n",
    "            self.model.add_module('dense' + str(i0), torch.nn.Linear(list_num_neurons[i0], list_num_neurons[i0+1]))\n",
    "            self.model.add_module('act' + str(i0), torch.nn.ReLU())\n",
    "            \n",
    "        #finally add softmax layer\n",
    "        self.model.add_module('dense' + str(i0+1), torch.nn.Linear(list_num_neurons[-2], list_num_neurons[-1]))\n",
    "        self.model.add_module('act' + str(i0+1), torch.nn.Softmax(dim=1))\n",
    "                         \n",
    "        \n",
    "        self.cost_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "        \n",
    "        #used to save results\n",
    "        self.result_data = torch.tensor([])\n",
    "        \n",
    "        #we keep a global step counter, thus that optimise can be called \n",
    "        #several times with different settings\n",
    "        self.epoch_counter = 0 \n",
    "        \n",
    "    def propagate(self, x):\n",
    "        \"\"\"\n",
    "        calculates the function estimation based on current parameters\n",
    "        \"\"\"            \n",
    "        y_pred = self.model(x)\n",
    "\n",
    "        return y_pred\n",
    "           \n",
    "     \n",
    "    def back_propagate(self, cost):\n",
    "        \"\"\"\n",
    "        calculates the backpropagation results based on expected output y\n",
    "        this function must be performed AFTER the corresponding propagte step\n",
    "        \"\"\"    \n",
    "        #set gradient values to zero\n",
    "        self.model.zero_grad()\n",
    "              \n",
    "        cost.backward()\n",
    " \n",
    "\n",
    "    def cost_funct(self, y_pred, y):\n",
    "        \"\"\"\n",
    "        calculates the MSE loss function\n",
    "        \"\"\"\n",
    "        cost = self.cost_fn(y_pred, y)\n",
    "        \n",
    "        return cost\n",
    "    \n",
    "         \n",
    "    def gradient_descend(self, alpha):\n",
    "        \"\"\"\n",
    "        does the gradient descend based on results from last back_prop step with learning rate alpha\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            self.optimizer.step()\n",
    "            \n",
    "         \n",
    "    def calc_error(self, y_pred, y):\n",
    "        \"\"\"\n",
    "        get error information\n",
    "        \"\"\"\n",
    "        m = y.shape[0]\n",
    "\n",
    "        y_pred_argmax = torch.argmax(y_pred, dim=1)\n",
    "        error = torch.sum(y != y_pred_argmax) / m\n",
    "\n",
    "        return error\n",
    "\n",
    "    \n",
    "    def append_result(self):\n",
    "        \"\"\"\n",
    "        append cost and error data to output array\n",
    "        \"\"\"\n",
    "        #this takes quite a long time (transform is applied to all images) but is only executed once \n",
    "        #then the images are available for quick execution of propagation step\n",
    "        if self.epoch_counter == 0: \n",
    "            # dataloaders (we use original set (training/test_data); own data has to realize the abstract class representing 'Dataset'\n",
    "            train_loader = torch.utils.data.DataLoader(self.data['train'], batch_size=len(self.data['train']), shuffle=False)\n",
    "            train_iterator = iter(train_loader)\n",
    "            self.train_images, self.train_labels = next(train_iterator)\n",
    "    \n",
    "            valid_loader = torch.utils.data.DataLoader(self.data['valid'], batch_size=len(self.data['valid']), shuffle=False)\n",
    "            valid_iterator = iter(valid_loader)\n",
    "            self.valid_images, self.valid_labels = next(valid_iterator)\n",
    "      \n",
    "        # determine cost and error functions for train and validation data\n",
    "        y_pred_train = self.propagate(self.train_images)\n",
    "        y_pred_val = self.propagate(self.valid_images)\n",
    "\n",
    "        res_data = torch.tensor([[self.cost_funct(y_pred_train, self.train_labels), \n",
    "                                  self.calc_error(y_pred_train, self.train_labels),\n",
    "                                  self.cost_funct(y_pred_val, self.valid_labels), \n",
    "                                  self.calc_error(y_pred_val, self.valid_labels)]])\n",
    "        \n",
    "        self.result_data = torch.cat((self.result_data, res_data), 0)\n",
    "\n",
    "        #send data to tensorboard   \n",
    "        writer.add_scalars('loss', {'train': res_data[0, 0].item(), \\\n",
    "                                   'validate': res_data[0, 2].item()}, self.epoch_counter)\n",
    "\n",
    "        writer.add_scalars('error',{'train': res_data[0, 1].item(), \\\n",
    "                                   'validate': res_data[0, 3].item()}, self.epoch_counter)\n",
    "\n",
    "        #increase epoch counter here (used for plot routines below)\n",
    "        self.epoch_counter += 1 \n",
    "        \n",
    "        return res_data\n",
    "\n",
    "        \n",
    "    def optimise(self, data, epochs, alpha, batch_size=0, debug=0):\n",
    "        \"\"\"\n",
    "        performs epochs number of gradient descend steps and appends result to output array\n",
    "\n",
    "        Arguments:\n",
    "        data -- dictionary with NORMALISED data\n",
    "        epochs -- number of epochs\n",
    "        alpha -- learning rate\n",
    "        batch_size -- size of batches (1 = SGD, 1 < .. < n = mini-batch)\n",
    "        debug -- integer value; get info on gradient descend step every debug-step (0 -> no output)\n",
    "        \"\"\"\n",
    "        #access to data from other methods\n",
    "        self.data = data\n",
    "\n",
    "        #we define the optimiser\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=alpha, momentum=0.)\n",
    "        #self.optimizer = torch.optim.Adam(self.model.parameters(), lr=alpha)\n",
    "\n",
    "        # dataloader for training image\n",
    "        train_loader = torch.utils.data.DataLoader(data['train'], batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # save results before 1st step\n",
    "        if self.epoch_counter == 0:\n",
    "            res_data = self.append_result()\n",
    "\n",
    "        for i0 in range(0, epochs):    \n",
    "            #measure time for one epoch\n",
    "            start=time.time()\n",
    "            #setup loop over all batchs\n",
    "            data_iterator = iter(train_loader)\n",
    "            for batch_iter in data_iterator:\n",
    "                #do prediction\n",
    "                y_pred = self.propagate(batch_iter[0])\n",
    "                #determine the loss \n",
    "                cost = self.cost_funct(y_pred, batch_iter[1])\n",
    "                #determine the error\n",
    "                self.back_propagate(cost)\n",
    "                #do the correction step\n",
    "                self.gradient_descend(alpha)\n",
    "\n",
    "            #save result\n",
    "            res_data = self.append_result()\n",
    "\n",
    "            #end of time measurement\n",
    "            end=time.time()\n",
    "            \n",
    "            if debug and np.mod(i0, debug) == 0:\n",
    "                print('result after %d epochs (dt=%1.2f s)' % (self.epoch_counter-1, end-start))\n",
    "\n",
    "        if debug:\n",
    "            print('result after %d epochs, train: cost %.5f, error %.5f ; validation: cost %.5f, error %.5f'\n",
    "                  % (self.epoch_counter-1, res_data[0, 0].item(), res_data[0, 1].item(), \\\n",
    "                                                                res_data[0, 2].item(), res_data[0, 3].item()))\n",
    "                        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcfae34-9c4a-461f-b06f-d9abc093b775",
   "metadata": {},
   "source": [
    "### Sample execution of Neural Network\n",
    "\n",
    "#### We split the creation and optimisation\n",
    "\n",
    "The cells below shows how to use the class NeuralNetwork and how to perform the optimisation. The training and test data is given as dictionary in the call to the method $optimise()$. The classes (from 2 to 10) can be chosen via the `classes` list. This method can be called several times in a row with different arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6bc169-8a62-4fc8-aab0-d88ab4b774d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the categories\n",
    "classes = torch.tensor([0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "#split data in train and validation\n",
    "validation_size = 0.2\n",
    "\n",
    "#further split in train and validation data\n",
    "validation_size = 0.2\n",
    "valid_ind = int(len(training_data)*(1-validation_size))\n",
    "\n",
    "#create custom training and validation data set\n",
    "train_dataset = MyDataset([training_data.data[:valid_ind,:], training_data.targets[:valid_ind]], classes=classes)\n",
    "valid_dataset = MyDataset([training_data.data[valid_ind:,:], training_data.targets[valid_ind:]], classes=classes)\n",
    "\n",
    "\n",
    "#data is arranged as dictionary with quick access through respective keys\n",
    "data = {'train' : train_dataset, 'valid' : valid_dataset}\n",
    "\n",
    "#choose the hyperparameters you want to use for the initialisation\n",
    "size_in = train_dataset[0][0].flatten().shape[0] #access to first image in torch.Subset train_data \n",
    "size_out = 10\n",
    "list_num_neurons = [size_in, 100, size_out]; \n",
    "NNet = NeuralNetwork(list_num_neurons)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d8abd4-b1bf-4e66-a2f8-4c689d945487",
   "metadata": {},
   "source": [
    "### Send the graph to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e92ed4-2f51-4b3f-a8d0-562c4ee6eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(NNet.model, my_images.float())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa03736-995c-49c5-8a36-ad1a23ce0436",
   "metadata": {},
   "source": [
    "### Add data for embedding to tensorboard \n",
    "\n",
    "Its more a gadget but nice to see \n",
    "(you may have to reload the tensorboard page or even restart the tensorboard in the console to see the `projector` icon on the task bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c79a503-7b9c-43e5-bdb4-48a7d560e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a larger set of images and labels\n",
    "num_samples = 200\n",
    "my_images = training_data.data[:num_samples]\n",
    "my_labels = training_data.targets[:num_samples]\n",
    "\n",
    "# log embeddings\n",
    "writer.add_embedding(my_images.view(-1, 28 * 28),\n",
    "                     metadata=my_labels,\n",
    "                     label_img=my_images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea58b8-3e3e-4132-8f4e-703b93331025",
   "metadata": {},
   "source": [
    "### Now run the training and observe the scalar output on tensorboard\n",
    "\n",
    "We see, that we can keep the code clean of any output and rely completely on tensorboard for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e5245-456f-4026-8978-8a1b8776ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the hyperparameters you want to use for training\n",
    "epochs = 100\n",
    "batchsize = 16\n",
    "learning_rate = 0.05\n",
    "NNet.optimise(data, epochs, learning_rate, batchsize, debug=5)\n",
    "\n",
    "#also prepare the test dataset\n",
    "test_dataset = MyDataset([test_data.data, test_data.targets], classes=classes)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "test_iterator = iter(test_loader)\n",
    "test_images, test_labels = next(test_iterator)\n",
    "\n",
    "y_pred = torch.argmax(NNet.propagate(test_images), axis=1)\n",
    "false_classifications = test_images[(y_pred != test_labels)]\n",
    "\n",
    "print('test error rate: %.2f %% out of %d' % (100*false_classifications.shape[0]/y_pred.shape[0], y_pred.shape[0]))\n",
    "print(false_classifications.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a650c507-d628-49f7-9f40-d18de2ddff57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
